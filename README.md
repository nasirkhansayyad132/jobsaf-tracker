# Jobs.af Tracker ğŸ’¼

A fully free, fully-online job tracker for IT/Tech jobs in Afghanistan.

- **PWA Mobile App** - Hosted on GitHub Pages, installable on Android
- **Daily Email Notifications** - New jobs & expiring jobs via Gmail
- **Automated Scraping** - GitHub Actions runs daily at 9:00 AM Kabul time

## Features

âœ… Tracks IT, Software, Data, and Computer Science jobs from jobs.af  
âœ… Mobile-first Progressive Web App (works offline)  
âœ… Search by title, company, location  
âœ… Filter: All, New, Expiring Today, Expiring Soon  
âœ… Shows apply links and emails extracted from job descriptions  
âœ… Daily email digest with new and expiring jobs  
âœ… 100% free using GitHub Actions + GitHub Pages  

## Tech Stack

- Frontend: React + Vite + Tailwind CSS + Framer Motion
- PWA: vite-plugin-pwa + service worker
- Scraper: Node.js + Puppeteer + puppeteer-extra stealth
- Automation: GitHub Actions + GitHub Pages
- Email: Python SMTP (Gmail)

## How It Works

1. GitHub Actions runs the Node scraper daily to update `docs/data/jobs.json`.
2. `scraper/generate_summary.js` builds `docs/data/summary.json`.
3. `scripts/notify_email.py` sends a daily digest via Gmail SMTP.
4. GitHub Pages serves the static PWA from `docs/`.

---

## ğŸ“± Setup Instructions (Android-Friendly)

### Step 1: Fork or Clone This Repository

Click **"Use this template"** or fork this repo to your GitHub account.

### Step 2: Enable GitHub Pages

1. Go to **Settings** â†’ **Pages**
2. Source: **Deploy from a branch**
3. Branch: **main**
4. Folder: **/docs**
5. Click **Save**

Your site will be available at: `https://YOUR-USERNAME.github.io/REPO-NAME/`

### Step 3: Add GitHub Secrets for Email Notifications

Go to **Settings** â†’ **Secrets and variables** â†’ **Actions** â†’ **New repository secret**

Add these secrets:

| Secret Name | Value |
|-------------|-------|
| `SMTP_HOST` | `smtp.gmail.com` |
| `SMTP_PORT` | `465` |
| `SMTP_USER` | Your Gmail address (e.g., `you@gmail.com`) |
| `SMTP_PASS` | Your Gmail App Password (see below) |
| `EMAIL_TO` | Recipient email address |

### Step 4: Create Gmail App Password

1. Go to [Google Account Security](https://myaccount.google.com/security)
2. Enable **2-Step Verification** if not already enabled
3. Go to [App Passwords](https://myaccount.google.com/apppasswords)
4. Select app: **Mail**, Select device: **Other** (type "Jobs.af")
5. Click **Generate**
6. Copy the 16-character password (e.g., `abcd efgh ijkl mnop`)
7. Use this as your `SMTP_PASS` secret (without spaces)

### Step 5: Run the Workflow Manually

1. Go to **Actions** tab
2. Click **Daily Jobs.af Scrape & Notify**
3. Click **Run workflow** â†’ **Run workflow**
4. Wait for it to complete (5-10 minutes)

### Step 6: Install on Android

1. Open your GitHub Pages URL in Chrome on Android
2. Tap the **â‹®** menu â†’ **Add to Home screen**
3. Name it "Jobs.af" and tap **Add**
4. Now you have a native app-like experience!

---

## ğŸ“ Repository Structure

```
/
â”œâ”€â”€ frontend/                # React + Vite source
â”‚   â”œâ”€â”€ src/                 # UI components
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ data/jobs.json   # Local dev data source
â”‚   â””â”€â”€ vite.config.js       # Builds into /docs
â”‚
â”œâ”€â”€ docs/                    # Built PWA (GitHub Pages output)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ sw.js
â”‚   â”œâ”€â”€ manifest.webmanifest
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ jobs.json
â”‚       â””â”€â”€ summary.json
â”‚
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ jobsaf_scrape.js     # Puppeteer scraper (primary)
â”‚   â”œâ”€â”€ generate_summary.js  # Builds summary.json
â”‚   â”œâ”€â”€ server.js            # Local API to trigger a scrape
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ notify_email.py      # Send email notifications
â”‚   â””â”€â”€ postprocess.py       # Optional processing utilities
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_jobs.json        # Raw scraper output
â”‚   â”œâ”€â”€ raw_jobs.csv         # CSV export
â”‚   â””â”€â”€ last_jobs.json       # Previous snapshot for diff
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ daily.yml            # Daily scrape + email + commit
â”‚   â””â”€â”€ scrape.yml           # Manual scrape run
â”‚
â”œâ”€â”€ jobsaf_url.txt           # Category URL reference
â””â”€â”€ scraper.py               # Legacy Playwright scraper (unused by workflows)
```

Note: `docs/` is generated by `npm run build` in `frontend/`. Avoid editing it by hand.

---

## âš™ï¸ Customization

### Change Job Categories

Update the jobs.af URL used by the scraper:
- `.github/workflows/daily.yml` (Run scraper step)
- `scraper/server.js` (local refresh API)
- `jobsaf_url.txt` (reference for manual runs)

### Change Pages Scanned

Adjust `--max-pages` in:
- `.github/workflows/daily.yml`
- `scraper/server.js`
- Your local `node jobsaf_scrape.js` command

### Change Schedule

Edit `.github/workflows/daily.yml`:

```yaml
schedule:
  # Cron format: minute hour day month weekday
  - cron: '30 4 * * *'  # 4:30 AM UTC = 9:00 AM Kabul
```

### Change Email Frequency

The workflow runs once daily. To run more frequently, add more cron schedules:

```yaml
schedule:
  - cron: '30 4 * * *'   # 9:00 AM Kabul
  - cron: '30 10 * * *'  # 3:00 PM Kabul
```

---

## ğŸ”§ Local Development

```bash
# Frontend (Vite)
cd frontend
npm install
npm run dev
# Open http://localhost:5173

# Build for GitHub Pages (writes to /docs)
npm run build
```

```bash
# Scraper (Node/Puppeteer)
cd ../scraper
npm install

# For local UI dev (writes to frontend/public/data/jobs.json)
node jobsaf_scrape.js --raw-url "<URL>" --max-pages 20 \
  --json ../frontend/public/data/jobs.json --csv ../data/jobs.csv

# For workflow-compatible output (writes to docs/data)
node jobsaf_scrape.js --raw-url "<URL>" --max-pages 20 \
  --json ../docs/data/jobs.json --csv ../data/jobs.csv

# Summary for email notifications
node generate_summary.js ../docs/data/jobs.json ../docs/data/summary.json ../data/last_jobs.json

# Optional: API server for the Refresh button
node server.js
```

---

## ğŸ“Š Data Format

### jobs.json

```json
[
  {
    "url": "https://jobs.af/jobs/example-job",
    "source": "jobs.af",
    "title": "Software Engineer",
    "company": "Tech Company",
    "location": "Kabul",
    "closing_date": "2026-01-25",
    "closing_date_raw": "Jan 25, 2026",
    "apply_url": "https://example.com/apply",
    "apply_emails": ["hr@example.com"],
    "apply_phones": ["+93 700 000 000"],
    "description": "Job description...",
    "details": {
      "Post Date": "Jan 15, 2026",
      "Salary Range": "Negotiable"
    },
    "scraped_at": "2026-01-17T12:00:00Z"
  }
]
```

### summary.json

```json
{
  "generated_at": "2026-01-17T13:30:00",
  "today": "2026-01-17",
  "total_jobs": 45,
  "new_count": 5,
  "expiring_today_count": 2,
  "expiring_soon_count": 8,
  "new_jobs": [...],
  "expiring_today": [...],
  "expiring_soon": [...]
}
```

---

## ğŸ› Troubleshooting

### Workflow fails with "No jobs found"

- jobs.af might be temporarily down
- The scraper might need updating if the site changed
- Check the debug screenshots in the workflow artifacts

### Email not sending

- Verify all SMTP secrets are set correctly
- Make sure you're using an App Password, not your regular password
- Check that 2-Step Verification is enabled on your Google account

### Refresh button does nothing (local dev)

- Start the API server: `node scraper/server.js`
- Make sure the frontend is running on `http://localhost:5173`

### PWA not installing

- Make sure you're using HTTPS (GitHub Pages provides this)
- Clear browser cache and try again
- Check that `manifest.webmanifest` is loading correctly

---

## ğŸ“„ License

MIT License - feel free to use, modify, and share!

---

## ğŸ™ Credits

- Data source: [jobs.af](https://jobs.af)
- Hosting: GitHub Pages (free)
- Automation: GitHub Actions (free)
- Icons: Emoji ğŸ˜Š
